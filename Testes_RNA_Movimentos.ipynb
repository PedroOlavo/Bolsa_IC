{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testes_RNA_Movimentos.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "16WNGSiHVkonHvdcCqn8wJlRroy-OdsaA",
      "authorship_tag": "ABX9TyO+9mMozdHLpHvbW4txU18x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PedroOlavo/Bolsa_IC/blob/main/Testes_RNA_Movimentos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcPOQbJSlKUt"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VO7ElGamBCi"
      },
      "source": [
        "# Teste dos movimentos canal 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "t91RIsj2lg7P",
        "outputId": "bb0e58ad-6703-4aac-91f4-4fe1bd8d8b9c"
      },
      "source": [
        "dados = pd.read_csv('/content/drive/MyDrive/BancodeDadosIC - Joelho/banco_movimentos_canal1')\n",
        "dados.drop(columns=['Unnamed: 0'], inplace=True) \n",
        "dados.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>...</th>\n",
              "      <th>362</th>\n",
              "      <th>363</th>\n",
              "      <th>364</th>\n",
              "      <th>365</th>\n",
              "      <th>366</th>\n",
              "      <th>367</th>\n",
              "      <th>368</th>\n",
              "      <th>369</th>\n",
              "      <th>370</th>\n",
              "      <th>371</th>\n",
              "      <th>372</th>\n",
              "      <th>373</th>\n",
              "      <th>374</th>\n",
              "      <th>375</th>\n",
              "      <th>376</th>\n",
              "      <th>377</th>\n",
              "      <th>378</th>\n",
              "      <th>379</th>\n",
              "      <th>380</th>\n",
              "      <th>381</th>\n",
              "      <th>382</th>\n",
              "      <th>383</th>\n",
              "      <th>384</th>\n",
              "      <th>385</th>\n",
              "      <th>386</th>\n",
              "      <th>387</th>\n",
              "      <th>388</th>\n",
              "      <th>389</th>\n",
              "      <th>390</th>\n",
              "      <th>391</th>\n",
              "      <th>392</th>\n",
              "      <th>393</th>\n",
              "      <th>394</th>\n",
              "      <th>395</th>\n",
              "      <th>396</th>\n",
              "      <th>397</th>\n",
              "      <th>398</th>\n",
              "      <th>399</th>\n",
              "      <th>400</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0060</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0075</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0217</td>\n",
              "      <td>0.0345</td>\n",
              "      <td>0.0375</td>\n",
              "      <td>0.0210</td>\n",
              "      <td>0.0060</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0157</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0172</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0202</td>\n",
              "      <td>0.0217</td>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0352</td>\n",
              "      <td>0.0420</td>\n",
              "      <td>0.0345</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0128</td>\n",
              "      <td>-0.0173</td>\n",
              "      <td>-0.0158</td>\n",
              "      <td>-0.0105</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0165</td>\n",
              "      <td>0.0127</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0060</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.0383</td>\n",
              "      <td>-0.0330</td>\n",
              "      <td>-0.0256</td>\n",
              "      <td>-0.0165</td>\n",
              "      <td>-0.0068</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0097</td>\n",
              "      <td>0.0142</td>\n",
              "      <td>0.0202</td>\n",
              "      <td>0.0195</td>\n",
              "      <td>0.0142</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0150</td>\n",
              "      <td>-0.0165</td>\n",
              "      <td>-0.0158</td>\n",
              "      <td>-0.0150</td>\n",
              "      <td>-0.0105</td>\n",
              "      <td>-0.0105</td>\n",
              "      <td>-0.0098</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0068</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0075</td>\n",
              "      <td>-0.0083</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>0.0112</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0060</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>-0.0083</td>\n",
              "      <td>-0.0150</td>\n",
              "      <td>-0.0181</td>\n",
              "      <td>-0.0218</td>\n",
              "      <td>-0.0210</td>\n",
              "      <td>-0.0128</td>\n",
              "      <td>-0.0120</td>\n",
              "      <td>-0.0165</td>\n",
              "      <td>-0.0128</td>\n",
              "      <td>-0.0181</td>\n",
              "      <td>-0.0233</td>\n",
              "      <td>-0.0158</td>\n",
              "      <td>-0.0105</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0075</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0127</td>\n",
              "      <td>0.0202</td>\n",
              "      <td>0.0255</td>\n",
              "      <td>0.0172</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0060</td>\n",
              "      <td>-0.0068</td>\n",
              "      <td>-0.0083</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0060</td>\n",
              "      <td>0.0075</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0112</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0142</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0127</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0113</td>\n",
              "      <td>-0.0173</td>\n",
              "      <td>-0.0218</td>\n",
              "      <td>-0.0195</td>\n",
              "      <td>-0.0165</td>\n",
              "      <td>-0.0128</td>\n",
              "      <td>-0.0105</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.0181</td>\n",
              "      <td>-0.0308</td>\n",
              "      <td>-0.0203</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0300</td>\n",
              "      <td>0.0307</td>\n",
              "      <td>0.0292</td>\n",
              "      <td>0.0270</td>\n",
              "      <td>0.0127</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0142</td>\n",
              "      <td>0.0075</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0203</td>\n",
              "      <td>-0.0383</td>\n",
              "      <td>-0.0405</td>\n",
              "      <td>-0.0315</td>\n",
              "      <td>-0.0173</td>\n",
              "      <td>-0.0113</td>\n",
              "      <td>-0.0181</td>\n",
              "      <td>-0.0330</td>\n",
              "      <td>-0.0518</td>\n",
              "      <td>-0.0615</td>\n",
              "      <td>-0.0465</td>\n",
              "      <td>-0.0278</td>\n",
              "      <td>-0.0083</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0292</td>\n",
              "      <td>0.0502</td>\n",
              "      <td>0.0652</td>\n",
              "      <td>0.0630</td>\n",
              "      <td>0.0540</td>\n",
              "      <td>0.0442</td>\n",
              "      <td>0.0345</td>\n",
              "      <td>0.0255</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0217</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.0068</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0060</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0015</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0157</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>-0.0120</td>\n",
              "      <td>-0.0165</td>\n",
              "      <td>-0.0203</td>\n",
              "      <td>-0.0195</td>\n",
              "      <td>-0.0143</td>\n",
              "      <td>-0.0075</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>-0.0060</td>\n",
              "      <td>-0.0120</td>\n",
              "      <td>-0.0158</td>\n",
              "      <td>-0.0195</td>\n",
              "      <td>-0.0135</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0142</td>\n",
              "      <td>0.0142</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0172</td>\n",
              "      <td>0.0187</td>\n",
              "      <td>0.0217</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0262</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0113</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>0.0097</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0097</td>\n",
              "      <td>0.0217</td>\n",
              "      <td>0.0337</td>\n",
              "      <td>0.0352</td>\n",
              "      <td>0.0322</td>\n",
              "      <td>0.0217</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>-0.0195</td>\n",
              "      <td>-0.0330</td>\n",
              "      <td>-0.0353</td>\n",
              "      <td>-0.0315</td>\n",
              "      <td>-0.0256</td>\n",
              "      <td>-0.0210</td>\n",
              "      <td>-0.0218</td>\n",
              "      <td>-0.0210</td>\n",
              "      <td>-0.0195</td>\n",
              "      <td>-0.0181</td>\n",
              "      <td>-0.0128</td>\n",
              "      <td>-0.0068</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0060</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>0.0112</td>\n",
              "      <td>0.0165</td>\n",
              "      <td>0.0202</td>\n",
              "      <td>0.0202</td>\n",
              "      <td>0.0217</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 401 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        1       2       3       4  ...     398     399     400  class\n",
              "0 -0.0046 -0.0053 -0.0060 -0.0046  ...  0.0352  0.0420  0.0345      0\n",
              "1  0.0067  0.0045 -0.0023 -0.0023  ... -0.0008 -0.0015  0.0015      0\n",
              "2  0.0007 -0.0038 -0.0046 -0.0038  ... -0.0128 -0.0105 -0.0091      0\n",
              "3 -0.0181 -0.0308 -0.0203  0.0030  ...  0.0007  0.0045  0.0067      0\n",
              "4  0.0015 -0.0015 -0.0053 -0.0030  ...  0.0202  0.0202  0.0217      0\n",
              "\n",
              "[5 rows x 401 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCB1y5mMlnT6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "y = dados['class']\n",
        "dados.drop(columns=['class'], inplace=True)\n",
        "x = dados\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.3, random_state=1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbU9eDXhl5co",
        "outputId": "88db6ebe-38e5-4e93-c434-6aff92a5b8c8"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit_transform(X_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.08703292,  0.14056697,  0.2425542 , ...,  0.00590565,\n",
              "         0.09296359,  0.0563095 ],\n",
              "       [-0.10499469, -0.03163953,  0.02959038, ...,  2.80980719,\n",
              "         2.2331514 ,  1.53774063],\n",
              "       [ 0.05960041,  0.06977097,  0.12086059, ..., -0.15945264,\n",
              "        -0.18141946, -0.18001404],\n",
              "       ...,\n",
              "       [ 0.08703292,  0.11186589,  0.07421137, ..., -0.04801553,\n",
              "        -0.07166624, -0.07419753],\n",
              "       [ 0.11446544,  0.14056697,  0.09043719, ..., -0.37154263,\n",
              "         0.03808698,  0.16212601],\n",
              "       [ 0.09983476,  0.06977097,  0.09043719, ..., -0.15945264,\n",
              "        -0.07166624, -0.07419753]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A_pcG99l7S2"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQICgAzWl-Kj",
        "outputId": "1959ad56-0ea7-4ebc-e9de-3481a2f8379d"
      },
      "source": [
        "ativações = ['relu', 'identity', 'logistic', 'tanh']\n",
        "layers = [(10,),(20,),(30,),(40,),(50,),(2,2),(3,3),(4,4),(5,5)]\n",
        "df = pd.DataFrame(columns=['Ativação','Camadas', 'Acurácia', 'Precisão', 'Recall', 'F1 Score'])\n",
        "i = 0\n",
        "for ativação in ativações:\n",
        "  i = i\n",
        "  for layer in layers:\n",
        "    lista = []\n",
        "    rede = MLPClassifier(activation=ativação,hidden_layer_sizes=layer,max_iter=300 ,random_state=1);\n",
        "    rede.fit(X_train,Y_train);\n",
        "    pred = rede.predict(X_test);\n",
        "    acc = accuracy_score(Y_test, pred);\n",
        "    prec = precision_score(Y_test, pred);\n",
        "    rec = recall_score(Y_test, pred);\n",
        "    f1 = f1_score(Y_test, pred);\n",
        "    lista.append(ativação)\n",
        "    lista.append(layer)\n",
        "    lista.append(acc)\n",
        "    lista.append(prec)\n",
        "    lista.append(rec)\n",
        "    lista.append(f1)\n",
        "    df.loc[i] = lista\n",
        "    i = i + 1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBS5ynknmAbI"
      },
      "source": [
        "df_tanh = df.loc[df['Ativação']=='tanh']\n",
        "df_relu = df.loc[df['Ativação']=='relu']\n",
        "df_identity = df.loc[df['Ativação']=='identity']\n",
        "df_logistic = df.loc[df['Ativação']=='logistic']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "O_A3_X9emU6R",
        "outputId": "849f9e8a-5030-4943-8966-880933e3cdd1"
      },
      "source": [
        "df_relu"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ativação</th>\n",
              "      <th>Camadas</th>\n",
              "      <th>Acurácia</th>\n",
              "      <th>Precisão</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>relu</td>\n",
              "      <td>(10,)</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.774194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>relu</td>\n",
              "      <td>(20,)</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.6875</td>\n",
              "      <td>0.733333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>relu</td>\n",
              "      <td>(30,)</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.774194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>relu</td>\n",
              "      <td>(40,)</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.774194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>relu</td>\n",
              "      <td>(50,)</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.774194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>relu</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>relu</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>relu</td>\n",
              "      <td>(4, 4)</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.812500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>relu</td>\n",
              "      <td>(5, 5)</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Ativação Camadas  Acurácia  Precisão  Recall  F1 Score\n",
              "0     relu   (10,)  0.708333  0.800000  0.7500  0.774194\n",
              "1     relu   (20,)  0.666667  0.785714  0.6875  0.733333\n",
              "2     relu   (30,)  0.708333  0.800000  0.7500  0.774194\n",
              "3     relu   (40,)  0.708333  0.800000  0.7500  0.774194\n",
              "4     relu   (50,)  0.708333  0.800000  0.7500  0.774194\n",
              "5     relu  (2, 2)  0.333333  0.000000  0.0000  0.000000\n",
              "6     relu  (3, 3)  0.666667  0.666667  1.0000  0.800000\n",
              "7     relu  (4, 4)  0.750000  0.812500  0.8125  0.812500\n",
              "8     relu  (5, 5)  0.750000  0.857143  0.7500  0.800000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH3HsK4Emht4"
      },
      "source": [
        "A melhor rede neste caso foi a relu com hidden_layer_sized=(5,5), max_iter=300 e teve 75% de acurácia e 85.7 de precisão "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igMlGeqdmzlL"
      },
      "source": [
        "# Teste canal 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "tOsrfgoImct8",
        "outputId": "4315ddcc-20e1-4626-a01a-a743a908a7e1"
      },
      "source": [
        "dados2 = pd.read_csv('/content/drive/MyDrive/BancodeDadosIC - Joelho/banco_movimentos_canal2')\n",
        "dados2.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "dados2.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>...</th>\n",
              "      <th>362</th>\n",
              "      <th>363</th>\n",
              "      <th>364</th>\n",
              "      <th>365</th>\n",
              "      <th>366</th>\n",
              "      <th>367</th>\n",
              "      <th>368</th>\n",
              "      <th>369</th>\n",
              "      <th>370</th>\n",
              "      <th>371</th>\n",
              "      <th>372</th>\n",
              "      <th>373</th>\n",
              "      <th>374</th>\n",
              "      <th>375</th>\n",
              "      <th>376</th>\n",
              "      <th>377</th>\n",
              "      <th>378</th>\n",
              "      <th>379</th>\n",
              "      <th>380</th>\n",
              "      <th>381</th>\n",
              "      <th>382</th>\n",
              "      <th>383</th>\n",
              "      <th>384</th>\n",
              "      <th>385</th>\n",
              "      <th>386</th>\n",
              "      <th>387</th>\n",
              "      <th>388</th>\n",
              "      <th>389</th>\n",
              "      <th>390</th>\n",
              "      <th>391</th>\n",
              "      <th>392</th>\n",
              "      <th>393</th>\n",
              "      <th>394</th>\n",
              "      <th>395</th>\n",
              "      <th>396</th>\n",
              "      <th>397</th>\n",
              "      <th>398</th>\n",
              "      <th>399</th>\n",
              "      <th>400</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.0038</td>\n",
              "      <td>-0.0068</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0060</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0097</td>\n",
              "      <td>0.0127</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0105</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0075</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0142</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0060</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0060</td>\n",
              "      <td>-0.0060</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0060</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0075</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0060</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0060</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0075</td>\n",
              "      <td>-0.0098</td>\n",
              "      <td>-0.0075</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0075</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0083</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0075</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0075</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0068</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0068</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0120</td>\n",
              "      <td>-0.0105</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0098</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0083</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.0068</td>\n",
              "      <td>-0.0181</td>\n",
              "      <td>-0.0128</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0075</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0127</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0112</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0068</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0068</td>\n",
              "      <td>-0.0105</td>\n",
              "      <td>-0.0113</td>\n",
              "      <td>-0.0113</td>\n",
              "      <td>-0.0068</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>-0.0060</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0068</td>\n",
              "      <td>-0.0060</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0068</td>\n",
              "      <td>-0.0075</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0060</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0097</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0083</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0060</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0128</td>\n",
              "      <td>-0.0113</td>\n",
              "      <td>-0.0060</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0060</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0097</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0097</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0098</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0112</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0083</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>-0.0083</td>\n",
              "      <td>-0.0113</td>\n",
              "      <td>-0.0075</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 401 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        1       2       3       4  ...     398     399     400  class\n",
              "0 -0.0038 -0.0068 -0.0053  0.0015  ...  0.0015  0.0030  0.0007      0\n",
              "1 -0.0053 -0.0060 -0.0046 -0.0038  ...  0.0007  0.0007  0.0007      0\n",
              "2 -0.0046 -0.0038 -0.0015 -0.0023  ... -0.0015  0.0015  0.0022      0\n",
              "3  0.0015  0.0007 -0.0008 -0.0008  ...  0.0045  0.0030  0.0007      0\n",
              "4 -0.0030 -0.0030 -0.0015  0.0000  ...  0.0007 -0.0008 -0.0046      0\n",
              "\n",
              "[5 rows x 401 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz3nQCrinC61"
      },
      "source": [
        "y = dados2['class']\n",
        "dados2.drop(columns=['class'], inplace=True)\n",
        "x = dados2\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.3, random_state=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9NAWsC3nMyg",
        "outputId": "3584249d-293e-4673-fa6b-2f514a423e92"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit_transform(X_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.36410942,  0.34269178,  0.17375832, ...,  2.51165388,\n",
              "         2.18560572,  1.64664125],\n",
              "       [-0.87613106, -0.71495594,  0.17375832, ..., -0.15775819,\n",
              "        -0.0440284 ,  0.08461002],\n",
              "       [ 2.24426121,  2.50756445,  2.35906543, ...,  2.73085742,\n",
              "         3.38749118,  3.35511291],\n",
              "       ...,\n",
              "       [-0.18344356, -0.16134346, -0.03257969, ..., -0.01162249,\n",
              "         0.00718831,  0.1334235 ],\n",
              "       [ 0.75993085,  0.64841807,  0.45512834, ...,  0.02734703,\n",
              "         0.00718831,  0.08461002],\n",
              "       [ 0.06724335, -0.0291375 , -0.03257969, ..., -0.23082603,\n",
              "        -0.22499411, -0.30589778]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-m4omo5nYpa",
        "outputId": "d02582d0-db4d-4d07-94b1-dd38873a92b1"
      },
      "source": [
        "ativações = ['relu', 'identity', 'logistic', 'tanh']\n",
        "layers = [(10,),(20,),(30,),(40,),(50,),(2,2),(3,3),(4,4),(5,5)]\n",
        "df2 = pd.DataFrame(columns=['Ativação','Camadas', 'Acurácia', 'Precisão', 'Recall', 'F1 Score'])\n",
        "i = 0\n",
        "for ativação in ativações:\n",
        "  i = i\n",
        "  for layer in layers:\n",
        "    lista = []\n",
        "    rede = MLPClassifier(activation=ativação,hidden_layer_sizes=layer,max_iter=300 ,random_state=1);\n",
        "    rede.fit(X_train,Y_train);\n",
        "    pred = rede.predict(X_test);\n",
        "    acc = accuracy_score(Y_test, pred);\n",
        "    prec = precision_score(Y_test, pred);\n",
        "    rec = recall_score(Y_test, pred);\n",
        "    f1 = f1_score(Y_test, pred);\n",
        "    lista.append(ativação)\n",
        "    lista.append(layer)\n",
        "    lista.append(acc)\n",
        "    lista.append(prec)\n",
        "    lista.append(rec)\n",
        "    lista.append(f1)\n",
        "    df2.loc[i] = lista\n",
        "    i = i + 1"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6SOdY7mneG3"
      },
      "source": [
        "df_tanh2 = df2.loc[df2['Ativação']=='tanh']\n",
        "df_relu2 = df2.loc[df2['Ativação']=='relu']\n",
        "df_identity2 = df2.loc[df2['Ativação']=='identity']\n",
        "df_logistic2 = df2.loc[df2['Ativação']=='logistic']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "yzwYa1T6njAV",
        "outputId": "c881e77f-9908-40a3-e641-36a213e267f2"
      },
      "source": [
        "df_tanh2"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ativação</th>\n",
              "      <th>Camadas</th>\n",
              "      <th>Acurácia</th>\n",
              "      <th>Precisão</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>tanh</td>\n",
              "      <td>(10,)</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.5625</td>\n",
              "      <td>0.620690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>tanh</td>\n",
              "      <td>(20,)</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.5625</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>tanh</td>\n",
              "      <td>(30,)</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.3750</td>\n",
              "      <td>0.480000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>tanh</td>\n",
              "      <td>(40,)</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.538462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>tanh</td>\n",
              "      <td>(50,)</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.518519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>tanh</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>tanh</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>tanh</td>\n",
              "      <td>(4, 4)</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.3750</td>\n",
              "      <td>0.461538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>tanh</td>\n",
              "      <td>(5, 5)</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.518519</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Ativação Camadas  Acurácia  Precisão  Recall  F1 Score\n",
              "27     tanh   (10,)      0.56  0.692308  0.5625  0.620690\n",
              "28     tanh   (20,)      0.52  0.642857  0.5625  0.600000\n",
              "29     tanh   (30,)      0.48  0.666667  0.3750  0.480000\n",
              "30     tanh   (40,)      0.52  0.700000  0.4375  0.538462\n",
              "31     tanh   (50,)      0.48  0.636364  0.4375  0.518519\n",
              "32     tanh  (2, 2)      0.36  0.000000  0.0000  0.000000\n",
              "33     tanh  (3, 3)      0.52  0.666667  0.5000  0.571429\n",
              "34     tanh  (4, 4)      0.44  0.600000  0.3750  0.461538\n",
              "35     tanh  (5, 5)      0.48  0.636364  0.4375  0.518519"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "aoO4LCWenkIU",
        "outputId": "ada5db34-9ea1-4796-fdd9-d17149293c6f"
      },
      "source": [
        "df_relu2"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ativação</th>\n",
              "      <th>Camadas</th>\n",
              "      <th>Acurácia</th>\n",
              "      <th>Precisão</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>relu</td>\n",
              "      <td>(10,)</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.6875</td>\n",
              "      <td>0.709677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>relu</td>\n",
              "      <td>(20,)</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>relu</td>\n",
              "      <td>(30,)</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.6250</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>relu</td>\n",
              "      <td>(40,)</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>relu</td>\n",
              "      <td>(50,)</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>relu</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>relu</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.780488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>relu</td>\n",
              "      <td>(4, 4)</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>relu</td>\n",
              "      <td>(5, 5)</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.538462</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Ativação Camadas  Acurácia  Precisão  Recall  F1 Score\n",
              "0     relu   (10,)      0.64  0.733333  0.6875  0.709677\n",
              "1     relu   (20,)      0.52  0.666667  0.5000  0.571429\n",
              "2     relu   (30,)      0.60  0.714286  0.6250  0.666667\n",
              "3     relu   (40,)      0.52  0.666667  0.5000  0.571429\n",
              "4     relu   (50,)      0.52  0.666667  0.5000  0.571429\n",
              "5     relu  (2, 2)      0.36  0.000000  0.0000  0.000000\n",
              "6     relu  (3, 3)      0.64  0.640000  1.0000  0.780488\n",
              "7     relu  (4, 4)      0.44  0.583333  0.4375  0.500000\n",
              "8     relu  (5, 5)      0.52  0.700000  0.4375  0.538462"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "ICv5Z0B5nl0Y",
        "outputId": "2b819c1b-b304-435f-ecda-b749d013dca6"
      },
      "source": [
        "df_logistic2"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ativação</th>\n",
              "      <th>Camadas</th>\n",
              "      <th>Acurácia</th>\n",
              "      <th>Precisão</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>logistic</td>\n",
              "      <td>(10,)</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.685714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>logistic</td>\n",
              "      <td>(20,)</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.5625</td>\n",
              "      <td>0.642857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>logistic</td>\n",
              "      <td>(30,)</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.5625</td>\n",
              "      <td>0.642857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>logistic</td>\n",
              "      <td>(40,)</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.5625</td>\n",
              "      <td>0.642857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>logistic</td>\n",
              "      <td>(50,)</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.5625</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>logistic</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>logistic</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.780488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>logistic</td>\n",
              "      <td>(4, 4)</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>logistic</td>\n",
              "      <td>(5, 5)</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Ativação Camadas  Acurácia  Precisão  Recall  F1 Score\n",
              "18  logistic   (10,)      0.56  0.631579  0.7500  0.685714\n",
              "19  logistic   (20,)      0.60  0.750000  0.5625  0.642857\n",
              "20  logistic   (30,)      0.60  0.750000  0.5625  0.642857\n",
              "21  logistic   (40,)      0.60  0.750000  0.5625  0.642857\n",
              "22  logistic   (50,)      0.64  0.818182  0.5625  0.666667\n",
              "23  logistic  (2, 2)      0.36  0.000000  0.0000  0.000000\n",
              "24  logistic  (3, 3)      0.64  0.640000  1.0000  0.780488\n",
              "25  logistic  (4, 4)      0.36  0.000000  0.0000  0.000000\n",
              "26  logistic  (5, 5)      0.36  0.000000  0.0000  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "dewfKosenniM",
        "outputId": "340b0739-a7ba-4ae7-a5ff-294a82638900"
      },
      "source": [
        "df_identity2"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ativação</th>\n",
              "      <th>Camadas</th>\n",
              "      <th>Acurácia</th>\n",
              "      <th>Precisão</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>identity</td>\n",
              "      <td>(10,)</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.5625</td>\n",
              "      <td>0.620690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>identity</td>\n",
              "      <td>(20,)</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.551724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>identity</td>\n",
              "      <td>(30,)</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.3750</td>\n",
              "      <td>0.480000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>identity</td>\n",
              "      <td>(40,)</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.538462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>identity</td>\n",
              "      <td>(50,)</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.518519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>identity</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.1875</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>identity</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.5625</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>identity</td>\n",
              "      <td>(4, 4)</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.518519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>identity</td>\n",
              "      <td>(5, 5)</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.4375</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Ativação Camadas  Acurácia  Precisão  Recall  F1 Score\n",
              "9   identity   (10,)      0.56  0.692308  0.5625  0.620690\n",
              "10  identity   (20,)      0.48  0.615385  0.5000  0.551724\n",
              "11  identity   (30,)      0.48  0.666667  0.3750  0.480000\n",
              "12  identity   (40,)      0.52  0.700000  0.4375  0.538462\n",
              "13  identity   (50,)      0.48  0.636364  0.4375  0.518519\n",
              "14  identity  (2, 2)      0.40  0.600000  0.1875  0.285714\n",
              "15  identity  (3, 3)      0.64  0.818182  0.5625  0.666667\n",
              "16  identity  (4, 4)      0.48  0.636364  0.4375  0.518519\n",
              "17  identity  (5, 5)      0.44  0.583333  0.4375  0.500000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TKUK19CnqM3"
      },
      "source": [
        "comparando os resultado me parece que o musculo presente no canal 1 é muito mais impactante que o do canal2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp-mM_Sen32J"
      },
      "source": [
        "# Testes canal 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh_Zl6KqnpNu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "ebf15401-ad53-4be1-8d3e-128ed6697121"
      },
      "source": [
        "dados3 = pd.read_csv('/content/drive/MyDrive/BancodeDadosIC - Joelho/banco_movimentos_canal3')\n",
        "dados3.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "dados3.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>...</th>\n",
              "      <th>362</th>\n",
              "      <th>363</th>\n",
              "      <th>364</th>\n",
              "      <th>365</th>\n",
              "      <th>366</th>\n",
              "      <th>367</th>\n",
              "      <th>368</th>\n",
              "      <th>369</th>\n",
              "      <th>370</th>\n",
              "      <th>371</th>\n",
              "      <th>372</th>\n",
              "      <th>373</th>\n",
              "      <th>374</th>\n",
              "      <th>375</th>\n",
              "      <th>376</th>\n",
              "      <th>377</th>\n",
              "      <th>378</th>\n",
              "      <th>379</th>\n",
              "      <th>380</th>\n",
              "      <th>381</th>\n",
              "      <th>382</th>\n",
              "      <th>383</th>\n",
              "      <th>384</th>\n",
              "      <th>385</th>\n",
              "      <th>386</th>\n",
              "      <th>387</th>\n",
              "      <th>388</th>\n",
              "      <th>389</th>\n",
              "      <th>390</th>\n",
              "      <th>391</th>\n",
              "      <th>392</th>\n",
              "      <th>393</th>\n",
              "      <th>394</th>\n",
              "      <th>395</th>\n",
              "      <th>396</th>\n",
              "      <th>397</th>\n",
              "      <th>398</th>\n",
              "      <th>399</th>\n",
              "      <th>400</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.0593</td>\n",
              "      <td>-0.0465</td>\n",
              "      <td>-0.0383</td>\n",
              "      <td>-0.0346</td>\n",
              "      <td>-0.0405</td>\n",
              "      <td>-0.0346</td>\n",
              "      <td>-0.0285</td>\n",
              "      <td>-0.0233</td>\n",
              "      <td>-0.0181</td>\n",
              "      <td>-0.0120</td>\n",
              "      <td>-0.0068</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0142</td>\n",
              "      <td>0.0195</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0255</td>\n",
              "      <td>0.0195</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0105</td>\n",
              "      <td>-0.0195</td>\n",
              "      <td>-0.0181</td>\n",
              "      <td>-0.0128</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0142</td>\n",
              "      <td>0.0195</td>\n",
              "      <td>0.0157</td>\n",
              "      <td>0.0165</td>\n",
              "      <td>0.0195</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0195</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0142</td>\n",
              "      <td>0.0157</td>\n",
              "      <td>0.0210</td>\n",
              "      <td>0.0270</td>\n",
              "      <td>0.0322</td>\n",
              "      <td>0.0285</td>\n",
              "      <td>0.0202</td>\n",
              "      <td>0.0127</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0255</td>\n",
              "      <td>0.0292</td>\n",
              "      <td>0.0292</td>\n",
              "      <td>0.0352</td>\n",
              "      <td>0.0367</td>\n",
              "      <td>0.0352</td>\n",
              "      <td>0.0352</td>\n",
              "      <td>0.0322</td>\n",
              "      <td>0.0255</td>\n",
              "      <td>0.0202</td>\n",
              "      <td>0.0225</td>\n",
              "      <td>0.0255</td>\n",
              "      <td>0.0255</td>\n",
              "      <td>0.0217</td>\n",
              "      <td>0.0195</td>\n",
              "      <td>0.0217</td>\n",
              "      <td>0.0277</td>\n",
              "      <td>0.0247</td>\n",
              "      <td>0.0172</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0097</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0165</td>\n",
              "      <td>0.0142</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0120</td>\n",
              "      <td>-0.0143</td>\n",
              "      <td>-0.0203</td>\n",
              "      <td>-0.0270</td>\n",
              "      <td>-0.0256</td>\n",
              "      <td>-0.0218</td>\n",
              "      <td>-0.0233</td>\n",
              "      <td>-0.0263</td>\n",
              "      <td>-0.0323</td>\n",
              "      <td>-0.0361</td>\n",
              "      <td>-0.0353</td>\n",
              "      <td>-0.0330</td>\n",
              "      <td>-0.0300</td>\n",
              "      <td>-0.0218</td>\n",
              "      <td>-0.0181</td>\n",
              "      <td>-0.0158</td>\n",
              "      <td>-0.0105</td>\n",
              "      <td>-0.0105</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0157</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0300</td>\n",
              "      <td>0.0240</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0127</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0127</td>\n",
              "      <td>0.0157</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0165</td>\n",
              "      <td>0.0217</td>\n",
              "      <td>0.0202</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0165</td>\n",
              "      <td>0.0112</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0083</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0120</td>\n",
              "      <td>-0.0165</td>\n",
              "      <td>-0.0098</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0157</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0097</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0075</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0075</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0157</td>\n",
              "      <td>0.0142</td>\n",
              "      <td>0.0112</td>\n",
              "      <td>0.0075</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0157</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0060</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0060</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.0105</td>\n",
              "      <td>-0.0143</td>\n",
              "      <td>-0.0165</td>\n",
              "      <td>-0.0165</td>\n",
              "      <td>-0.0120</td>\n",
              "      <td>-0.0105</td>\n",
              "      <td>-0.0181</td>\n",
              "      <td>-0.0195</td>\n",
              "      <td>-0.0210</td>\n",
              "      <td>-0.0203</td>\n",
              "      <td>-0.0150</td>\n",
              "      <td>-0.0135</td>\n",
              "      <td>-0.0181</td>\n",
              "      <td>-0.0210</td>\n",
              "      <td>-0.0143</td>\n",
              "      <td>-0.0113</td>\n",
              "      <td>-0.0113</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0083</td>\n",
              "      <td>-0.0068</td>\n",
              "      <td>-0.0060</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0097</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0127</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0105</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0158</td>\n",
              "      <td>-0.0293</td>\n",
              "      <td>-0.0405</td>\n",
              "      <td>-0.0315</td>\n",
              "      <td>-0.0233</td>\n",
              "      <td>-0.0181</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>0.0060</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0142</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0202</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0083</td>\n",
              "      <td>-0.0105</td>\n",
              "      <td>-0.0105</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0112</td>\n",
              "      <td>0.0165</td>\n",
              "      <td>0.0202</td>\n",
              "      <td>0.0142</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0195</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0097</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0097</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.0623</td>\n",
              "      <td>-0.0668</td>\n",
              "      <td>-0.0653</td>\n",
              "      <td>-0.0615</td>\n",
              "      <td>-0.0638</td>\n",
              "      <td>-0.0533</td>\n",
              "      <td>-0.0458</td>\n",
              "      <td>-0.0383</td>\n",
              "      <td>-0.0315</td>\n",
              "      <td>-0.0308</td>\n",
              "      <td>-0.0248</td>\n",
              "      <td>-0.0218</td>\n",
              "      <td>-0.0158</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>-0.0068</td>\n",
              "      <td>-0.0075</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0015</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0030</td>\n",
              "      <td>-0.0023</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0172</td>\n",
              "      <td>0.0187</td>\n",
              "      <td>0.0127</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0127</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0405</td>\n",
              "      <td>0.0367</td>\n",
              "      <td>0.0375</td>\n",
              "      <td>0.0405</td>\n",
              "      <td>0.0420</td>\n",
              "      <td>0.0442</td>\n",
              "      <td>0.0480</td>\n",
              "      <td>0.0502</td>\n",
              "      <td>0.0532</td>\n",
              "      <td>0.0525</td>\n",
              "      <td>0.0532</td>\n",
              "      <td>0.0607</td>\n",
              "      <td>0.0577</td>\n",
              "      <td>0.0525</td>\n",
              "      <td>0.0427</td>\n",
              "      <td>0.0360</td>\n",
              "      <td>0.0360</td>\n",
              "      <td>0.0240</td>\n",
              "      <td>0.0202</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>-0.0128</td>\n",
              "      <td>-0.0270</td>\n",
              "      <td>-0.0323</td>\n",
              "      <td>-0.0300</td>\n",
              "      <td>-0.0368</td>\n",
              "      <td>-0.0390</td>\n",
              "      <td>-0.0450</td>\n",
              "      <td>-0.0503</td>\n",
              "      <td>-0.0488</td>\n",
              "      <td>-0.0533</td>\n",
              "      <td>-0.0495</td>\n",
              "      <td>-0.0465</td>\n",
              "      <td>-0.0465</td>\n",
              "      <td>-0.0458</td>\n",
              "      <td>-0.0488</td>\n",
              "      <td>-0.0503</td>\n",
              "      <td>-0.0511</td>\n",
              "      <td>-0.0533</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.0600</td>\n",
              "      <td>-0.0585</td>\n",
              "      <td>-0.0503</td>\n",
              "      <td>-0.0346</td>\n",
              "      <td>-0.0210</td>\n",
              "      <td>-0.0263</td>\n",
              "      <td>-0.0330</td>\n",
              "      <td>-0.0405</td>\n",
              "      <td>-0.0375</td>\n",
              "      <td>-0.0113</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0060</td>\n",
              "      <td>-0.0135</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0240</td>\n",
              "      <td>0.0165</td>\n",
              "      <td>-0.0128</td>\n",
              "      <td>-0.0353</td>\n",
              "      <td>-0.0495</td>\n",
              "      <td>-0.0600</td>\n",
              "      <td>-0.0660</td>\n",
              "      <td>-0.0653</td>\n",
              "      <td>-0.0555</td>\n",
              "      <td>-0.0293</td>\n",
              "      <td>-0.0091</td>\n",
              "      <td>-0.0105</td>\n",
              "      <td>-0.0053</td>\n",
              "      <td>-0.0046</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0172</td>\n",
              "      <td>0.0157</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0352</td>\n",
              "      <td>0.0465</td>\n",
              "      <td>0.0465</td>\n",
              "      <td>0.0420</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 401 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        1       2       3       4  ...     398     399     400  class\n",
              "0 -0.0593 -0.0465 -0.0383 -0.0346  ...  0.0135  0.0097  0.0067      0\n",
              "1  0.0150  0.0180  0.0165  0.0142  ...  0.0015  0.0105  0.0157      0\n",
              "2  0.0097  0.0030  0.0030  0.0030  ...  0.0037  0.0105  0.0127      0\n",
              "3 -0.0053 -0.0091 -0.0105 -0.0091  ...  0.0127  0.0120  0.0127      0\n",
              "4  0.0405  0.0367  0.0375  0.0405  ...  0.0465  0.0465  0.0420      0\n",
              "\n",
              "[5 rows x 401 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-KWh0F5oFe-"
      },
      "source": [
        "y = dados3['class']\n",
        "dados3.drop(columns=['class'], inplace=True)\n",
        "x = dados3\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.3, random_state=1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr9pug9ZoT88",
        "outputId": "9f041f23-ddd1-4dde-fe08-062db4ed4478"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit_transform(X_train)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.15695914, -0.15823756, -0.13607621, ..., -0.36319705,\n",
              "        -0.44201707, -0.42112846],\n",
              "       [-0.24075122, -0.22464617, -0.24939139, ..., -0.39465831,\n",
              "        -0.22224379, -0.21651607],\n",
              "       [ 1.34221245,  1.63479487,  1.0966934 , ..., -0.77219344,\n",
              "        -0.86481898, -1.02248927],\n",
              "       ...,\n",
              "       [ 0.12268432,  0.13285351,  0.09678027, ...,  2.26276953,\n",
              "         2.06967748,  2.46091194],\n",
              "       [-0.17210228, -0.17483971, -0.15475453, ..., -0.39465831,\n",
              "        -0.41062088, -0.42112846],\n",
              "       [-0.15695914, -0.14938308, -0.12735965, ..., -0.48904209,\n",
              "        -0.50480943, -0.66566522]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2B2R3rkoXKC",
        "outputId": "ba984d62-a3d1-4e98-c046-7a82b13e9d12"
      },
      "source": [
        "ativações = ['relu', 'identity', 'logistic', 'tanh']\n",
        "layers = [(10,),(20,),(30,),(40,),(50,),(2,2),(3,3),(4,4),(5,5)]\n",
        "df3 = pd.DataFrame(columns=['Ativação','Camadas', 'Acurácia', 'Precisão', 'Recall', 'F1 Score'])\n",
        "i = 0\n",
        "for ativação in ativações:\n",
        "  i = i\n",
        "  for layer in layers:\n",
        "    lista = []\n",
        "    rede = MLPClassifier(activation=ativação,hidden_layer_sizes=layer,max_iter=300 ,random_state=1);\n",
        "    rede.fit(X_train,Y_train);\n",
        "    pred = rede.predict(X_test);\n",
        "    acc = accuracy_score(Y_test, pred);\n",
        "    prec = precision_score(Y_test, pred);\n",
        "    rec = recall_score(Y_test, pred);\n",
        "    f1 = f1_score(Y_test, pred);\n",
        "    lista.append(ativação)\n",
        "    lista.append(layer)\n",
        "    lista.append(acc)\n",
        "    lista.append(prec)\n",
        "    lista.append(rec)\n",
        "    lista.append(f1)\n",
        "    df3.loc[i] = lista\n",
        "    i = i + 1"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SAZ5lTSob6V"
      },
      "source": [
        "df_tanh3 = df3.loc[df3['Ativação']=='tanh']\n",
        "df_relu3 = df3.loc[df3['Ativação']=='relu']\n",
        "df_identity3 = df3.loc[df3['Ativação']=='identity']\n",
        "df_logistic3 = df3.loc[df3['Ativação']=='logistic']"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "uJ3dZgm0ohgm",
        "outputId": "bda6365a-bff8-40ce-cef5-1ea1d6c7eae2"
      },
      "source": [
        "df_tanh3"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ativação</th>\n",
              "      <th>Camadas</th>\n",
              "      <th>Acurácia</th>\n",
              "      <th>Precisão</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>tanh</td>\n",
              "      <td>(10,)</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.608696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>tanh</td>\n",
              "      <td>(20,)</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>tanh</td>\n",
              "      <td>(30,)</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>tanh</td>\n",
              "      <td>(40,)</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.615385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>tanh</td>\n",
              "      <td>(50,)</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.615385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>tanh</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>tanh</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.583333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>tanh</td>\n",
              "      <td>(4, 4)</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>tanh</td>\n",
              "      <td>(5, 5)</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.583333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Ativação Camadas  Acurácia  Precisão    Recall  F1 Score\n",
              "27     tanh   (10,)  0.666667  0.875000  0.466667  0.608696\n",
              "28     tanh   (20,)  0.592593  0.700000  0.466667  0.560000\n",
              "29     tanh   (30,)  0.592593  0.700000  0.466667  0.560000\n",
              "30     tanh   (40,)  0.629630  0.727273  0.533333  0.615385\n",
              "31     tanh   (50,)  0.629630  0.727273  0.533333  0.615385\n",
              "32     tanh  (2, 2)  0.555556  0.800000  0.266667  0.400000\n",
              "33     tanh  (3, 3)  0.629630  0.777778  0.466667  0.583333\n",
              "34     tanh  (4, 4)  0.592593  0.700000  0.466667  0.560000\n",
              "35     tanh  (5, 5)  0.629630  0.777778  0.466667  0.583333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "5DwFsu4gorYV",
        "outputId": "0e4801ae-0292-47be-e0aa-e03ebf7bf174"
      },
      "source": [
        "df_relu3"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ativação</th>\n",
              "      <th>Camadas</th>\n",
              "      <th>Acurácia</th>\n",
              "      <th>Precisão</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>relu</td>\n",
              "      <td>(10,)</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.608696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>relu</td>\n",
              "      <td>(20,)</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.454545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>relu</td>\n",
              "      <td>(30,)</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.583333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>relu</td>\n",
              "      <td>(40,)</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.521739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>relu</td>\n",
              "      <td>(50,)</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.521739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>relu</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>relu</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.516129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>relu</td>\n",
              "      <td>(4, 4)</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.538462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>relu</td>\n",
              "      <td>(5, 5)</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.583333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Ativação Camadas  Acurácia  Precisão    Recall  F1 Score\n",
              "0     relu   (10,)  0.666667  0.875000  0.466667  0.608696\n",
              "1     relu   (20,)  0.555556  0.714286  0.333333  0.454545\n",
              "2     relu   (30,)  0.629630  0.777778  0.466667  0.583333\n",
              "3     relu   (40,)  0.592593  0.750000  0.400000  0.521739\n",
              "4     relu   (50,)  0.592593  0.750000  0.400000  0.521739\n",
              "5     relu  (2, 2)  0.444444  0.000000  0.000000  0.000000\n",
              "6     relu  (3, 3)  0.444444  0.500000  0.533333  0.516129\n",
              "7     relu  (4, 4)  0.555556  0.636364  0.466667  0.538462\n",
              "8     relu  (5, 5)  0.629630  0.777778  0.466667  0.583333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "pRNIiZMjosTZ",
        "outputId": "e78b113d-dde5-4628-b990-e6fb2c9da95e"
      },
      "source": [
        "df_identity3"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ativação</th>\n",
              "      <th>Camadas</th>\n",
              "      <th>Acurácia</th>\n",
              "      <th>Precisão</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>identity</td>\n",
              "      <td>(10,)</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.608696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>identity</td>\n",
              "      <td>(20,)</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.583333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>identity</td>\n",
              "      <td>(30,)</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>identity</td>\n",
              "      <td>(40,)</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.615385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>identity</td>\n",
              "      <td>(50,)</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>identity</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>identity</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.608696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>identity</td>\n",
              "      <td>(4, 4)</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>identity</td>\n",
              "      <td>(5, 5)</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.583333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Ativação Camadas  Acurácia  Precisão    Recall  F1 Score\n",
              "9   identity   (10,)  0.666667  0.875000  0.466667  0.608696\n",
              "10  identity   (20,)  0.629630  0.777778  0.466667  0.583333\n",
              "11  identity   (30,)  0.592593  0.700000  0.466667  0.560000\n",
              "12  identity   (40,)  0.629630  0.727273  0.533333  0.615385\n",
              "13  identity   (50,)  0.592593  0.700000  0.466667  0.560000\n",
              "14  identity  (2, 2)  0.555556  0.800000  0.266667  0.400000\n",
              "15  identity  (3, 3)  0.666667  0.875000  0.466667  0.608696\n",
              "16  identity  (4, 4)  0.592593  0.700000  0.466667  0.560000\n",
              "17  identity  (5, 5)  0.629630  0.777778  0.466667  0.583333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "zEcGVH3bouAr",
        "outputId": "aac9f230-768c-47a5-930f-82785f377d36"
      },
      "source": [
        "df_logistic3"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ativação</th>\n",
              "      <th>Camadas</th>\n",
              "      <th>Acurácia</th>\n",
              "      <th>Precisão</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>logistic</td>\n",
              "      <td>(10,)</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.608696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>logistic</td>\n",
              "      <td>(20,)</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.545455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>logistic</td>\n",
              "      <td>(30,)</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.545455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>logistic</td>\n",
              "      <td>(40,)</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.545455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>logistic</td>\n",
              "      <td>(50,)</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.583333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>logistic</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>logistic</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>logistic</td>\n",
              "      <td>(4, 4)</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.545455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>logistic</td>\n",
              "      <td>(5, 5)</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.545455</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Ativação Camadas  Acurácia  Precisão    Recall  F1 Score\n",
              "18  logistic   (10,)  0.666667  0.875000  0.466667  0.608696\n",
              "19  logistic   (20,)  0.629630  0.857143  0.400000  0.545455\n",
              "20  logistic   (30,)  0.629630  0.857143  0.400000  0.545455\n",
              "21  logistic   (40,)  0.629630  0.857143  0.400000  0.545455\n",
              "22  logistic   (50,)  0.629630  0.777778  0.466667  0.583333\n",
              "23  logistic  (2, 2)  0.444444  0.000000  0.000000  0.000000\n",
              "24  logistic  (3, 3)  0.555556  0.555556  1.000000  0.714286\n",
              "25  logistic  (4, 4)  0.629630  0.857143  0.400000  0.545455\n",
              "26  logistic  (5, 5)  0.629630  0.857143  0.400000  0.545455"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN5cC91VovCt"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    }
  ]
}